"""
Doris API Gateway - ä¸»ç¨‹åº
"""
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional
import uvicorn
import traceback
import os

from config import API_HOST, API_PORT, DORIS_CONFIG
from handlers import action_handler
from db import doris_client
from upload_handler import excel_handler
from vanna_doris import VannaDorisOpenAI
from datasource_handler import datasource_handler, sync_scheduler
from metadata_analyzer import metadata_analyzer

app = FastAPI(
    title="Doris API Gateway",
    description="æç®€çš„ HTTP API Gateway for Apache Doris",
    version="1.0.0"
)

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============ å¯åŠ¨äº‹ä»¶ ============

@app.on_event("startup")
async def startup_event():
    """
    åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“
    """
    import time
    import pymysql

    max_retries = 30
    retry_interval = 2

    print("=" * 60)
    print("ğŸš€ Doris API Gateway å¯åŠ¨ä¸­...")
    print("=" * 60)

    # ç­‰å¾… Doris FE å°±ç»ª
    for i in range(max_retries):
        try:
            print(f"â³ ç­‰å¾… Doris FE å°±ç»ª... ({i+1}/{max_retries})")

            # å°è¯•è¿æ¥åˆ° Doris (ä¸æŒ‡å®šæ•°æ®åº“)
            conn = pymysql.connect(
                host=DORIS_CONFIG['host'],
                port=DORIS_CONFIG['port'],
                user=DORIS_CONFIG['user'],
                password=DORIS_CONFIG['password'],
                connect_timeout=5
            )

            cursor = conn.cursor()
            
            # 1. æ£€æŸ¥å¹¶æ³¨å†Œ BE (é’ˆå¯¹æ–°ç¯å¢ƒåˆå§‹åŒ–)
            cursor.execute("SHOW BACKENDS")
            backends = cursor.fetchall()
            if not backends:
                be_host = os.getenv('DORIS_STREAM_LOAD_HOST', 'doris-be')
                be_heartbeat_port = 9050 # é»˜è®¤å¿ƒè·³ç«¯å£
                print(f"âš™ï¸  æœªå‘ç°å·²æ³¨å†Œçš„ BE, å°è¯•è‡ªåŠ¨æ³¨å†Œ: {be_host}:{be_heartbeat_port}")
                try:
                    cursor.execute(f'ALTER SYSTEM ADD BACKEND "{be_host}:{be_heartbeat_port}"')
                    print(f"âœ… å·²å‘é€æ³¨å†Œ BE æŒ‡ä»¤: {be_host}:{be_heartbeat_port}")
                    # æ³¨å†Œåç»™ä¸€ç‚¹æ—¶é—´è®© BE å°±ç»ª
                    time.sleep(5)
                except Exception as be_err:
                    print(f"âš ï¸  æ³¨å†Œ BE å¤±è´¥ (å¯èƒ½å·²å­˜åœ¨æˆ–æ­£åœ¨åˆå§‹åŒ–): {be_err}")

            # 2. åˆ›å»ºæ•°æ®åº“
            db_name = DORIS_CONFIG['database']
            print(f"ğŸ“¦ åˆ›å»ºæ•°æ®åº“: {db_name}")
            cursor.execute(f"CREATE DATABASE IF NOT EXISTS `{db_name}`")
            
            # éªŒè¯æ•°æ®åº“åˆ›å»ºæˆåŠŸ
            cursor.execute("SHOW DATABASES")
            databases = [row[0] for row in cursor.fetchall()]

            if db_name in databases:
                print(f"âœ… æ•°æ®åº“ '{db_name}' å·²å°±ç»ª")
            else:
                print(f"âš ï¸  æ•°æ®åº“ '{db_name}' åˆ›å»ºå¤±è´¥")

            cursor.close()
            conn.close()

            # åˆå§‹åŒ–ç³»ç»Ÿè¡¨
            datasource_handler.init_tables()
            print("âœ… ç³»ç»Ÿè¡¨å·²åˆå§‹åŒ–")

            print("=" * 60)
            print("âœ… Doris API Gateway å¯åŠ¨æˆåŠŸ!")
            print(f"ğŸ“Š æ•°æ®åº“: {db_name}")
            print(f"ğŸŒ API åœ°å€: http://{API_HOST}:{API_PORT}")
            print(f"ğŸ“– API æ–‡æ¡£: http://{API_HOST}:{API_PORT}/docs")
            print("=" * 60)
            break

        except Exception as e:
            if i < max_retries - 1:
                print(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
                print(f"â³ {retry_interval} ç§’åé‡è¯•...")
                time.sleep(retry_interval)
            else:
                print("=" * 60)
                print("âŒ æ— æ³•è¿æ¥åˆ° Doris FE,è¯·æ£€æŸ¥é…ç½®")
                print(f"é”™è¯¯: {str(e)}")
                print("=" * 60)
                raise

    # å¯åŠ¨åŒæ­¥è°ƒåº¦å™¨
    sync_scheduler.start()


# ============ æ•°æ®æ¨¡å‹ ============

class ExecuteRequest(BaseModel):
    """ç»Ÿä¸€æ‰§è¡Œè¯·æ±‚"""
    action: str = Field(..., description="æ“ä½œç±»å‹: query/sentiment/classify/extract/stats/similarity/translate/summarize/mask/fixgrammar/generate/filter")
    table: Optional[str] = Field(None, description="è¡¨å")
    column: Optional[str] = Field(None, description="åˆ—å")
    params: Optional[Dict[str, Any]] = Field(default_factory=dict, description="å…¶ä»–å‚æ•°")
    
    class Config:
        json_schema_extra = {
            "example": {
                "action": "sentiment",
                "table": "customer_feedback",
                "column": "feedback_text",
                "params": {
                    "limit": 50
                }
            }
        }


class LLMConfigRequest(BaseModel):
    """LLM é…ç½®è¯·æ±‚"""
    resource_name: str = Field(..., description="èµ„æºåç§°")
    provider_type: str = Field(..., description="å‚å•†ç±»å‹: openai/deepseek/qwen/zhipu/localç­‰")
    endpoint: str = Field(..., description="API ç«¯ç‚¹")
    model_name: str = Field(..., description="æ¨¡å‹åç§°")
    api_key: Optional[str] = Field(None, description="API å¯†é’¥")
    temperature: Optional[float] = Field(None, description="æ¸©åº¦å‚æ•° 0-1")
    max_tokens: Optional[int] = Field(None, description="æœ€å¤§ token æ•°")

    class Config:
        json_schema_extra = {
            "example": {
                "resource_name": "my_openai",
                "provider_type": "openai",
                "endpoint": "https://api.openai.com/v1/chat/completions",
                "model_name": "gpt-4",
                "api_key": "sk-xxxxx"
            }
        }


class NLQueryRequest(BaseModel):
    """è‡ªç„¶è¯­è¨€æŸ¥è¯¢è¯·æ±‚"""
    question: str = Field(..., description="è‡ªç„¶è¯­è¨€é—®é¢˜")
    table_name: str = Field(..., description="ç›®æ ‡è¡¨å")
    resource_name: Optional[str] = Field(None, description="LLM èµ„æºåç§°,ä¸æŒ‡å®šåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨èµ„æº")

    class Config:
        json_schema_extra = {
            "example": {
                "question": "2022å¹´çš„æœºæ„ä¸­æ¥è‡ªäºå¹¿ä¸œçš„æœ‰å¤šå°‘ä¸ª?åˆ†åˆ«æ˜¯æ¥è‡ªäºå¹¿ä¸œé‚£å‡ ä¸ªåŸå¸‚æ¯ä¸ªåŸå¸‚çš„å æ¯”æ˜¯å¤šå°‘?",
                "table_name": "ä¸­å›½ç¯ä¿å…¬ç›Šç»„ç»‡ç°çŠ¶è°ƒç ”æ•°æ®2022.",
                "resource_name": "my_deepseek"
            }
        }


# ============ API è·¯ç”± ============

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "service": "Doris API Gateway",
        "status": "running",
        "version": "1.0.0"
    }


@app.get("/api/health")
async def health_check():
    """æ£€æŸ¥ Doris è¿æ¥çŠ¶æ€"""
    try:
        result = doris_client.execute_query("SELECT 1 AS health")
        return {
            "success": True,
            "doris_connected": True,
            "message": "Doris connection OK"
        }
    except Exception as e:
        return {
            "success": False,
            "doris_connected": False,
            "error": str(e)
        }


@app.post("/api/execute")
async def execute_action(req: ExecuteRequest):
    """
    ç»Ÿä¸€æ‰§è¡Œæ¥å£
    
    æ”¯æŒçš„ action:
    - query: æ™®é€šæŸ¥è¯¢
    - sentiment: æƒ…æ„Ÿåˆ†æ
    - classify: æ–‡æœ¬åˆ†ç±»
    - extract: ä¿¡æ¯æå–
    - stats: ç»Ÿè®¡åˆ†æ
    - similarity: è¯­ä¹‰ç›¸ä¼¼åº¦
    - translate: æ–‡æœ¬ç¿»è¯‘
    - summarize: æ–‡æœ¬æ‘˜è¦
    - mask: æ•æ„Ÿä¿¡æ¯è„±æ•
    - fixgrammar: è¯­æ³•çº é”™
    - generate: å†…å®¹ç”Ÿæˆ
    - filter: å¸ƒå°”è¿‡æ»¤
    """
    try:
        # åˆå¹¶å‚æ•°
        params = req.params or {}
        if req.table:
            params['table'] = req.table
        if req.column:
            params['column'] = req.column
        
        # æ‰§è¡Œæ“ä½œ
        result = action_handler.execute(req.action, params)
        return result
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        )


@app.get("/api/tables")
async def list_tables():
    """è·å–æ‰€æœ‰è¡¨"""
    try:
        tables = doris_client.get_tables()
        return {
            "success": True,
            "tables": tables,
            "count": len(tables)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tables/{table_name}/schema")
async def get_table_schema(table_name: str):
    """è·å–è¡¨ç»“æ„"""
    try:
        schema = doris_client.get_table_schema(table_name)
        return {
            "success": True,
            "table": table_name,
            "schema": schema
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/llm/config")
async def create_llm_config(req: LLMConfigRequest):
    """åˆ›å»º LLM é…ç½®"""
    try:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"=== Received request: provider={req.provider_type}, endpoint={req.endpoint}, model={req.model_name}")

        # æ„é€  CREATE RESOURCE SQL (Doris 4.0 ä½¿ç”¨ 'ai' ç±»å‹å’Œ 'ai.' å‰ç¼€)
        properties = [
            "'type' = 'ai'",
            f"'ai.provider_type' = '{req.provider_type}'",
            f"'ai.endpoint' = '{req.endpoint}'",
            f"'ai.model_name' = '{req.model_name}'"
        ]

        if req.api_key:
            properties.append(f"'ai.api_key' = '{req.api_key}'")
        if req.temperature is not None:
            properties.append(f"'ai.temperature' = {req.temperature}")
        if req.max_tokens is not None:
            properties.append(f"'ai.max_tokens' = {req.max_tokens}")
        
        properties_str = ',\n    '.join(properties)
        
        sql = f"""
        CREATE RESOURCE '{req.resource_name}'
        PROPERTIES (
            {properties_str}
        )
        """

        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"=== Creating LLM Resource SQL: {sql}")

        doris_client.execute_update(sql)
        
        return {
            "success": True,
            "message": f"LLM resource '{req.resource_name}' created successfully",
            "sql": sql
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        )


@app.get("/api/llm/config")
async def list_llm_configs():
    """è·å–æ‰€æœ‰ LLM é…ç½®"""
    try:
        # Doris 4.0 çš„ SHOW RESOURCES è¯­æ³•,ä½¿ç”¨ NAME LIKE è·å–æ‰€æœ‰èµ„æº
        sql = 'SHOW RESOURCES WHERE NAME LIKE "%"'
        all_resources = doris_client.execute_query(sql)

        # SHOW RESOURCES è¿”å›çš„æ˜¯æ¯ä¸ªèµ„æºçš„æ¯ä¸ªå±æ€§ä½œä¸ºä¸€è¡Œ
        # éœ€è¦æŒ‰èµ„æºåç§°åˆ†ç»„,å¹¶è¿‡æ»¤å‡º AI ç±»å‹çš„èµ„æº
        resources_dict = {}
        for row in all_resources:
            name = row.get('Name')
            resource_type = row.get('ResourceType')

            # åªå¤„ç† AI ç±»å‹çš„èµ„æº
            if resource_type != 'ai':
                continue

            # åˆå§‹åŒ–èµ„æºå¯¹è±¡ (ä½¿ç”¨å‰ç«¯æœŸæœ›çš„å­—æ®µå)
            if name not in resources_dict:
                resources_dict[name] = {
                    'ResourceName': name,
                    'ResourceType': resource_type,
                    'properties': {}
                }

            # æ”¶é›†å±æ€§
            item = row.get('Item')
            value = row.get('Value')
            if item and value:
                resources_dict[name]['properties'][item] = value

        # è½¬æ¢ä¸ºåˆ—è¡¨
        llm_resources = list(resources_dict.values())

        return {
            "success": True,
            "resources": llm_resources,
            "count": len(llm_resources)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/llm/config/{resource_name}/test")
async def test_llm_config(resource_name: str):
    """æµ‹è¯• LLM é…ç½®"""
    try:
        # ä½¿ç”¨ç®€å•çš„æµ‹è¯•æŸ¥è¯¢ (Doris 4.0 ä½¿ç”¨ AI_GENERATE å‡½æ•°)
        sql = f"SELECT AI_GENERATE('{resource_name}', 'Hello') AS test_result"
        result = doris_client.execute_query(sql)
        
        return {
            "success": True,
            "message": "LLM resource is working",
            "test_result": result[0] if result else None
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "success": False,
                "error": str(e)
            }
        )


@app.delete("/api/llm/config/{resource_name}")
async def delete_llm_config(resource_name: str):
    """åˆ é™¤ LLM é…ç½®"""
    try:
        sql = f"DROP RESOURCE '{resource_name}'"
        doris_client.execute_update(sql)

        return {
            "success": True,
            "message": f"LLM resource '{resource_name}' deleted successfully"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/query/natural")
async def natural_language_query(request: Dict[str, Any]):
    """
    è‡ªç„¶è¯­è¨€æŸ¥è¯¢æ¥å£ (Agent-to-Agent) - ä½¿ç”¨ Vanna.AI

    å‰ç«¯ Agent ä¼ å…¥è‡ªç„¶è¯­è¨€é—®é¢˜,ç³»ç»Ÿä½¿ç”¨ Vanna.AI ç”Ÿæˆ SQL å¹¶æ‰§è¡ŒæŸ¥è¯¢

    Request Body:
        {
            "query": "2022å¹´çš„æœºæ„ä¸­æ¥è‡ªäºå¹¿ä¸œçš„æœ‰å¤šå°‘ä¸ª?åˆ†åˆ«æ˜¯æ¥è‡ªäºå¹¿ä¸œé‚£å‡ ä¸ªåŸå¸‚æ¯ä¸ªåŸå¸‚çš„å æ¯”æ˜¯å¤šå°‘?",
            "api_key": "sk-xxx",  // å¯é€‰,é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
            "model": "deepseek-chat",  // å¯é€‰,é»˜è®¤ deepseek-chat
            "base_url": "https://api.deepseek.com"  // å¯é€‰,é»˜è®¤ DeepSeek API
        }

    Response:
        {
            "success": true,
            "query": "åŸå§‹é—®é¢˜",
            "sql": "ç”Ÿæˆçš„ SQL",
            "data": [...],
            "count": æ•°æ®è¡Œæ•°
        }
    """
    try:
        query = request.get('query')
        if not query:
            raise HTTPException(status_code=400, detail="Missing 'query' parameter")

        # è·å– API é…ç½®
        api_key = request.get('api_key') or os.getenv('DEEPSEEK_API_KEY') or os.getenv('OPENAI_API_KEY')
        model = request.get('model') or os.getenv('DEEPSEEK_MODEL', 'deepseek-chat')
        base_url = request.get('base_url') or os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')

        if not api_key:
            raise HTTPException(
                status_code=400,
                detail="API key not provided. Please provide 'api_key' in request or set DEEPSEEK_API_KEY/OPENAI_API_KEY environment variable"
            )

        import logging
        logger = logging.getLogger(__name__)
        logger.info(f"=== Natural language query: {query}")
        logger.info(f"=== Using model: {model} at {base_url}")

        # åˆå§‹åŒ– Vanna
        vanna = VannaDorisOpenAI(
            doris_client=doris_client,
            api_key=api_key,
            model=model,
            base_url=base_url,
            config={'temperature': 0.1}  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœ
        )

        # ä½¿ç”¨ Vanna ç”Ÿæˆ SQL
        logger.info("=== Generating SQL with Vanna.AI...")
        generated_sql = vanna.generate_sql(question=query)

        logger.info(f"=== Generated SQL: {generated_sql}")

        # æ‰§è¡Œç”Ÿæˆçš„ SQL
        query_result = vanna.run_sql(generated_sql)

        logger.info(f"=== Query executed successfully, returned {len(query_result)} rows")

        return {
            "success": True,
            "query": query,
            "sql": generated_sql,
            "data": query_result,
            "count": len(query_result)
        }

    except HTTPException:
        raise
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"=== Error in natural language query: {str(e)}")
        logger.error(traceback.format_exc())

        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        )


@app.post("/api/upload/preview")
async def preview_excel_file(file: UploadFile = File(...), rows: int = 10):
    """é¢„è§ˆ Excel æ–‡ä»¶"""
    try:
        content = await file.read()
        result = excel_handler.preview_excel(content, rows)

        return {
            "success": True,
            "filename": file.filename,
            **result
        }
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        )


async def _analyze_table_async(table_name: str, source_type: str):
    """å¼‚æ­¥åˆ†æè¡¨æ ¼å…ƒæ•°æ®"""
    import asyncio
    await asyncio.sleep(2)  # ç­‰å¾…æ•°æ®å®Œå…¨å†™å…¥
    try:
        result = metadata_analyzer.analyze_table(table_name, source_type)
        if result.get('success'):
            print(f"âœ… è¡¨æ ¼ '{table_name}' å…ƒæ•°æ®åˆ†æå®Œæˆ")
        else:
            print(f"âš ï¸ è¡¨æ ¼ '{table_name}' å…ƒæ•°æ®åˆ†æå¤±è´¥: {result.get('error')}")
    except Exception as e:
        print(f"âŒ å…ƒæ•°æ®åˆ†æå¼‚å¸¸: {e}")


@app.post("/api/upload")
async def upload_excel(
    file: UploadFile = File(...),
    table_name: str = Form(...),
    column_mapping: Optional[str] = Form(None),
    create_table: str = Form("true")
):
    """
    ä¸Šä¼  Excel æ–‡ä»¶å¹¶å¯¼å…¥åˆ° Doris

    Args:
        file: Excel æ–‡ä»¶
        table_name: ç›®æ ‡è¡¨å
        column_mapping: åˆ—æ˜ å°„ JSON å­—ç¬¦ä¸² (å¯é€‰)
        create_table: å¦‚æœè¡¨ä¸å­˜åœ¨æ˜¯å¦åˆ›å»º (å­—ç¬¦ä¸² "true"/"false")
    """
    try:
        import json

        content = await file.read()

        # è§£æåˆ—æ˜ å°„
        mapping = None
        if column_mapping:
            mapping = json.loads(column_mapping)

        # è½¬æ¢ create_table å­—ç¬¦ä¸²ä¸ºå¸ƒå°”å€¼
        create_table_bool = create_table.lower() in ('true', '1', 'yes')

        result = excel_handler.import_excel(
            file_content=content,
            table_name=table_name,
            column_mapping=mapping,
            create_table_if_not_exists=create_table_bool
        )

        # è‡ªåŠ¨è§¦å‘å…ƒæ•°æ®åˆ†æï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡è¿”å›ï¼‰
        try:
            import asyncio
            asyncio.create_task(_analyze_table_async(table_name, 'excel'))
        except Exception as analyze_error:
            print(f"âš ï¸ å…ƒæ•°æ®åˆ†æè§¦å‘å¤±è´¥: {analyze_error}")

        return result

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail={
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        )


# ============ æ•°æ®æºåŒæ­¥ API ============

class DataSourceTestRequest(BaseModel):
    """æ•°æ®æºè¿æ¥æµ‹è¯•è¯·æ±‚"""
    host: str = Field(..., description="æ•°æ®åº“ä¸»æœº")
    port: int = Field(..., description="æ•°æ®åº“ç«¯å£")
    user: str = Field(..., description="ç”¨æˆ·å")
    password: str = Field(..., description="å¯†ç ")
    database: Optional[str] = Field(None, description="æ•°æ®åº“å")


class DataSourceSaveRequest(BaseModel):
    """ä¿å­˜æ•°æ®æºè¯·æ±‚"""
    name: str = Field(..., description="æ•°æ®æºåç§°")
    host: str = Field(..., description="æ•°æ®åº“ä¸»æœº")
    port: int = Field(..., description="æ•°æ®åº“ç«¯å£")
    user: str = Field(..., description="ç”¨æˆ·å")
    password: str = Field(..., description="å¯†ç ")
    database: str = Field(..., description="æ•°æ®åº“å")


class SyncTableRequest(BaseModel):
    """åŒæ­¥è¡¨è¯·æ±‚"""
    source_table: str = Field(..., description="æºè¡¨å")
    target_table: Optional[str] = Field(None, description="ç›®æ ‡è¡¨å")


class SyncMultipleRequest(BaseModel):
    """æ‰¹é‡åŒæ­¥è¯·æ±‚"""
    tables: List[Dict[str, str]] = Field(..., description="è¦åŒæ­¥çš„è¡¨åˆ—è¡¨")


@app.post("/api/datasource/test")
async def test_datasource_connection(req: DataSourceTestRequest):
    """æµ‹è¯•æ•°æ®æºè¿æ¥"""
    result = datasource_handler.test_connection(
        host=req.host,
        port=req.port,
        user=req.user,
        password=req.password,
        database=req.database
    )
    return result


@app.post("/api/datasource")
async def save_datasource(req: DataSourceSaveRequest):
    """ä¿å­˜æ•°æ®æºé…ç½®"""
    try:
        result = datasource_handler.save_datasource(
            name=req.name,
            host=req.host,
            port=req.port,
            user=req.user,
            password=req.password,
            database=req.database
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/datasource")
async def list_datasources():
    """è·å–æ‰€æœ‰æ•°æ®æº"""
    try:
        datasources = datasource_handler.list_datasources()
        return {
            "success": True,
            "datasources": datasources,
            "count": len(datasources)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/datasource/{ds_id}")
async def delete_datasource(ds_id: str):
    """åˆ é™¤æ•°æ®æº"""
    try:
        result = datasource_handler.delete_datasource(ds_id)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/datasource/{ds_id}/tables")
async def get_datasource_tables(ds_id: str):
    """è·å–æ•°æ®æºä¸­çš„è¡¨åˆ—è¡¨"""
    try:
        print(f"ğŸ“‹ è·å–æ•°æ®æºè¡¨åˆ—è¡¨: ds_id={ds_id}")
        ds = datasource_handler.get_datasource(ds_id)
        print(f"ğŸ“‹ æ•°æ®æºä¿¡æ¯: {ds}")
        if not ds:
            raise HTTPException(status_code=404, detail="æ•°æ®æºä¸å­˜åœ¨")

        result = datasource_handler.get_remote_tables(
            host=ds['host'],
            port=ds['port'],
            user=ds['user'],
            password=ds['password'],
            database=ds['database_name']
        )
        print(f"ğŸ“‹ è·å–è¡¨åˆ—è¡¨ç»“æœ: {result}")
        return result
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        print(f"âŒ è·å–è¡¨åˆ—è¡¨å¼‚å¸¸: {str(e)}")
        print(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/datasource/{ds_id}/sync")
async def sync_datasource_table(ds_id: str, req: SyncTableRequest):
    """åŒæ­¥å•ä¸ªè¡¨"""
    try:
        result = datasource_handler.sync_table(
            ds_id=ds_id,
            source_table=req.source_table,
            target_table=req.target_table
        )
        if not result.get('success'):
            raise HTTPException(status_code=500, detail=result.get('error'))

        # è‡ªåŠ¨è§¦å‘å…ƒæ•°æ®åˆ†æ
        target = req.target_table or req.source_table
        try:
            import asyncio
            asyncio.create_task(_analyze_table_async(target, 'database_sync'))
        except Exception as analyze_error:
            print(f"âš ï¸ å…ƒæ•°æ®åˆ†æè§¦å‘å¤±è´¥: {analyze_error}")

        return result
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/datasource/{ds_id}/sync-multiple")
async def sync_multiple_tables(ds_id: str, req: SyncMultipleRequest):
    """æ‰¹é‡åŒæ­¥å¤šä¸ªè¡¨"""
    try:
        result = datasource_handler.sync_multiple_tables(
            ds_id=ds_id,
            tables=req.tables
        )

        # ä¸ºæ¯ä¸ªæˆåŠŸåŒæ­¥çš„è¡¨è§¦å‘å…ƒæ•°æ®åˆ†æ
        if result.get('results'):
            import asyncio
            for table_result in result['results']:
                if table_result.get('success'):
                    target = table_result.get('target_table')
                    try:
                        asyncio.create_task(_analyze_table_async(target, 'database_sync'))
                    except Exception as e:
                        print(f"âš ï¸ å…ƒæ•°æ®åˆ†æè§¦å‘å¤±è´¥: {e}")

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============ è¡¨é¢„è§ˆ API ============

@app.get("/api/datasource/{ds_id}/tables/{table_name}/preview")
async def preview_datasource_table(ds_id: str, table_name: str, limit: int = 100):
    """é¢„è§ˆè¿œç¨‹è¡¨çš„ç»“æ„å’Œæ•°æ®"""
    try:
        ds = datasource_handler.get_datasource(ds_id)
        if not ds:
            raise HTTPException(status_code=404, detail="æ•°æ®æºä¸å­˜åœ¨")

        result = datasource_handler.preview_remote_table(
            host=ds['host'],
            port=ds['port'],
            user=ds['user'],
            password=ds['password'],
            database=ds['database_name'],
            table_name=table_name,
            limit=limit
        )
        return result
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============ åŒæ­¥ä»»åŠ¡è°ƒåº¦ API ============

class ScheduleSyncRequest(BaseModel):
    """å®šæ—¶åŒæ­¥è¯·æ±‚ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    datasource_id: str = Field(..., description="æ•°æ®æºID")
    source_table: str = Field(..., description="æºè¡¨å")
    target_table: Optional[str] = Field(None, description="ç›®æ ‡è¡¨å")
    schedule_type: str = Field(..., description="è°ƒåº¦ç±»å‹: hourly/daily/weekly/monthly")
    schedule_minute: Optional[int] = Field(0, description="åˆ†é’Ÿ (0-59)")
    schedule_hour: Optional[int] = Field(0, description="å°æ—¶ (0-23)")
    schedule_day_of_week: Optional[int] = Field(1, description="å‘¨å‡  (1-7, 1=å‘¨ä¸€)")
    schedule_day_of_month: Optional[int] = Field(1, description="æ—¥æœŸ (1-31)")
    enabled_for_ai: Optional[bool] = Field(True, description="æ˜¯å¦å¯ç”¨AIåˆ†æ")


class UpdateSyncTaskRequest(BaseModel):
    """æ›´æ–°åŒæ­¥ä»»åŠ¡è¯·æ±‚"""
    schedule_type: Optional[str] = Field(None, description="è°ƒåº¦ç±»å‹")
    schedule_minute: Optional[int] = Field(None, description="åˆ†é’Ÿ")
    schedule_hour: Optional[int] = Field(None, description="å°æ—¶")
    schedule_day_of_week: Optional[int] = Field(None, description="å‘¨å‡ ")
    schedule_day_of_month: Optional[int] = Field(None, description="æ—¥æœŸ")
    enabled_for_ai: Optional[bool] = Field(None, description="æ˜¯å¦å¯ç”¨AIåˆ†æ")


@app.post("/api/sync/schedule")
async def create_sync_schedule(req: ScheduleSyncRequest):
    """åˆ›å»ºå®šæ—¶åŒæ­¥ä»»åŠ¡"""
    try:
        result = datasource_handler.save_sync_task(
            ds_id=req.datasource_id,
            source_table=req.source_table,
            target_table=req.target_table,
            schedule_type=req.schedule_type,
            schedule_minute=req.schedule_minute or 0,
            schedule_hour=req.schedule_hour or 0,
            schedule_day_of_week=req.schedule_day_of_week or 1,
            schedule_day_of_month=req.schedule_day_of_month or 1,
            enabled_for_ai=req.enabled_for_ai if req.enabled_for_ai is not None else True
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/sync/tasks/{task_id}")
async def update_sync_task(task_id: str, req: UpdateSyncTaskRequest):
    """æ›´æ–°åŒæ­¥ä»»åŠ¡é…ç½®"""
    try:
        result = datasource_handler.update_sync_task(
            task_id=task_id,
            schedule_type=req.schedule_type,
            schedule_minute=req.schedule_minute,
            schedule_hour=req.schedule_hour,
            schedule_day_of_week=req.schedule_day_of_week,
            schedule_day_of_month=req.schedule_day_of_month,
            enabled_for_ai=req.enabled_for_ai
        )
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/sync/tasks/{task_id}/toggle-ai")
async def toggle_task_ai(task_id: str, enabled: bool):
    """åˆ‡æ¢åŒæ­¥ä»»åŠ¡çš„AIåˆ†æå¯ç”¨çŠ¶æ€"""
    try:
        result = datasource_handler.toggle_ai_enabled(task_id, enabled)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/sync/tasks")
async def list_sync_tasks():
    """è·å–æ‰€æœ‰åŒæ­¥ä»»åŠ¡"""
    try:
        tasks = datasource_handler.list_sync_tasks()
        return {
            "success": True,
            "tasks": tasks,
            "count": len(tasks)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/sync/ai-enabled-tables")
async def get_ai_enabled_tables():
    """è·å–æ‰€æœ‰å¯ç”¨AIåˆ†æçš„è¡¨å"""
    try:
        tables = datasource_handler.get_ai_enabled_tables()
        return {
            "success": True,
            "tables": tables,
            "count": len(tables)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/sync/tasks/{task_id}")
async def delete_sync_task(task_id: str):
    """åˆ é™¤åŒæ­¥ä»»åŠ¡"""
    try:
        result = datasource_handler.delete_sync_task(task_id)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============ å…ƒæ•°æ®åˆ†æ API ============

@app.post("/api/tables/{table_name}/analyze")
async def analyze_table_metadata(table_name: str, source_type: str = "manual"):
    """åˆ†æè¡¨æ ¼å…ƒæ•°æ®"""
    try:
        result = metadata_analyzer.analyze_table(table_name, source_type)
        if not result.get('success'):
            raise HTTPException(status_code=500, detail=result.get('error'))
        return result
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/tables/{table_name}/metadata")
async def get_table_metadata(table_name: str):
    """è·å–è¡¨æ ¼å…ƒæ•°æ®"""
    try:
        metadata = metadata_analyzer.get_metadata(table_name)
        if not metadata:
            return {
                "success": True,
                "metadata": None,
                "message": "è¡¨æ ¼å°šæœªåˆ†æï¼Œè¯·å…ˆè°ƒç”¨åˆ†ææ¥å£"
            }
        return {
            "success": True,
            "metadata": metadata
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/metadata")
async def list_all_metadata():
    """è·å–æ‰€æœ‰è¡¨æ ¼å…ƒæ•°æ®"""
    try:
        metadata_list = metadata_analyzer.list_all_metadata()
        return {
            "success": True,
            "metadata": metadata_list,
            "count": len(metadata_list)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=API_HOST,
        port=API_PORT,
        reload=True
    )

